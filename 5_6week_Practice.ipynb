{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9190d9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa7399",
   "metadata": {},
   "source": [
    "# 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d6a066",
   "metadata": {},
   "source": [
    "<span style = 'font-size:1.3em;line-height:1.5em'><b>1. </b>실습파일 '3_Transfer_Learning.ipynb'에서 활용한 데이터로 Resnet18모델에 대해서 transfer learning을 수행해보세요. 단, 동일한 실습파일에서 수행한 방식처럼 마지막 fc layer에 대해서만 fine-tuning하는 방식으로 수행해보세요.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91c3493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets.folder import ImageFolder\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe87990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SANDBOX\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\SANDBOX\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\SANDBOX\\anaconda3\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:858: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24, Loss: 0.0030\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋의 변환 정의\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# 데이터셋 로딩\n",
    "dataset_path = 'data/cats_and_dogs/PetImages/'  \n",
    "\n",
    "dataset = ImageFolder(root=dataset_path, transform=data_transforms)\n",
    "\n",
    "# 트레이닝과 검증 인덱스 분할\n",
    "def create_splits(dataset, train_size=0.8):\n",
    "    num_train = int(len(dataset) * train_size)\n",
    "    indices = list(range(len(dataset)))\n",
    "    np.random.shuffle(indices)\n",
    "    train_indices, val_indices = indices[:num_train], indices[num_train:]\n",
    "    return train_indices, val_indices\n",
    "\n",
    "train_indices, val_indices = create_splits(dataset)\n",
    "\n",
    "# DataLoader 설정\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=32, sampler=train_sampler)\n",
    "val_loader = DataLoader(dataset, batch_size=32, sampler=val_sampler)\n",
    "\n",
    "# ResNet18 모델 로딩 및 수정\n",
    "model = models.resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # 기존 파라미터는 고정\n",
    "\n",
    "# 마지막 fc 레이어 교체\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)  # 클래스 수를 2로 설정\n",
    "\n",
    "# 모델을 사용할 device 설정 (CUDA가 사용 가능하면 GPU 사용)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 손실 함수 및 옵티마이저 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)  # fc 레이어의 파라미터만 최적화\n",
    "\n",
    "# 학습 함수 정의\n",
    "def train_model(model, criterion, optimizer, num_epochs=25):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # 모델을 트레이닝 모드로 설정\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # 에포크별 손실률 출력\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}, Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        # 여기에 검증 과정을 추가할 수 있습니다.\n",
    "    return model\n",
    "\n",
    "# 모델 학습\n",
    "model_trained = train_model(model, criterion, optimizer, num_epochs=25)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
